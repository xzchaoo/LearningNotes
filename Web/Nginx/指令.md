1. error_log
	1. 用于记录错误日志
	2. 如果要关闭日志则: error_log /dev/null crit;

include file
	1. 引入其他配置文件
	2. 如果是相对目录, 则是相对于当前配置文件

user user [group]; 
	1. nginx的子进程以user和group的身份运行
	2. 新版本的nginx还有 cache manager process 和  cache loader process 进程.


worker_processes
	1. 工作者进程数
worker_cpu_affinity
	1. 用于将进程绑定到某个CPU上
worker_priority
	1. 工作者优先级

```
events{
	worker_connections 1024; 每个工作者最多可以有多少个连接	
	debug_connection ip|CIDR ; 编译的时候必须  --with-debug, 对于这些ip的客户端, 会记录更详细的日志
	use epoll; 使用哪种事件模型, 具体比较复杂, 有需要的话再去了解.
}
```
```
http {
	其他配置;
	server{可以有多个server
		其他配置 + 从http上继承的配置;
		listen 80; //监听80端口, 还可以设置ssl
		#listen [addrs:]port [default_server] [backlog=num] [ssl]
		server_name example.com *.example.com;
		#这个name用于匹配请求来的时候选择哪个虚拟主机进行路由
		#优先级: 精确匹配 形如*.abc.com 形如 www.abc.* 正则表达式 带有默认属性的区段;
		location / {可以有多个server
			其他配置 + 从server继承的配置.
			root html;//相对于${prefix}的目录, 用作该访问的起始路径, 如果访问了 /images/1.jpg 则映射到 ${prefix}/html/images/1.jpg
			index index.html index.php; 指定一些index文件
		}
	}
}
alais与root的区别
假设: 目录a下有一个1.jpg, 目录b下有一个1.jpg
location /a{
	alias a;
}
location /b {
	root b;
}
访问 /a/1.jpg 实际上找的是 a/1.jpg文件
访问 /b/1.jpg 实际上找的是 b/b/1.jpg文件
另外alias还可以这样用:
location ~ ^/download/(.*)$ {
	alias /var/www/files/$1;
}
当你访问 /download/1.jpg 则对应的是 /var/www/files/1.jpg
```


client_body_buffer_size
client_body_temp_path
client_body/header_timeout
client_max_body_size
default_type 用于设定一个默认的MIME

error_page
	1. 用于设定遇到了错误要怎么办
	2. 比如你可以显示一个404.html
	3. 将该请求 fallback 到后面的服务器

internal;
	1. 用于location, 表明该location内部使用, 不能通过url直接访问
	2. 比如: error_page 404 @notfound;
	3. location @notfound{...}

keepalive_timeout
keepalive_requests 服务器能够保持 keepalive 的连接数


limit_except GET POST {
	allow 192.168.1.0/24;
	deny all;
}
limit_rate 限制流量
limit_rate_after


log_not_found
	磁盘上文件找不到的时候是否向error_log记录日志, 比如访问 /a/1.jpg 但找不到 1.jpg

log_subrequest
	是否对子请求记录日志
	子请求是 rewrite或ssi产生的请求
	
open_file_cache
open_file_cache_errors
open_file_cache_min_uses
open_file_cache_valid

satisfy [all|any]

try_files path1 path2 path3;
方式访问所有path, 返回第一个找到的文件;
try_files $uri $uri/ /index.php?q=$uri&$args; 因为$args不会自动被添加
```
try_files 停机维护.html $uri $uri/index.html @xxx;
...
location @xxx{
	proxy_pass http://...
}
```
变量
$arg_key 查询GET请求的参数
$args 整个queryString
$binary_remote_addr 二进制形式的客户端地址
$body_bytes_sent
$content_length
$cookie_name
$document_root 对应的location里的root的值
$uri
$host
$hostname
$header_name
$is_args 是否设置了$args
$limit_rate
$remote_addr
$remote_port
$remote_user
$nginx_version
$request_file
$request_body
$request_method
$request_uri
$scheme
$server-addr
$server_name
$server_port



# 模块管理 #
如果要增加删除模块只能重新编译
通过./configure --help可以看到哪些模块是默认安装的
有 -with-xxx  的就表明xxx模块默认不安装
--without-xxx 表明xxx模块默认安装
如果两者都有, 那么应该是根据操作系统的情况来自行选择了

引入第三方模块
--add-module=/path/to/module

# 针对Linux的优化 #
1. 关闭Linux不必要的服务
2. 优化写磁盘操作
	1. 关闭Linux的自动写atime
3. 设置可以打开的文件的个数, 即文件描述符数量, 默认是1024
	1. 到 /etc/security/limits.conf 配置
	2. 可以用 ulimit -n查看fd个数 ulimit -u 查看进程个数
4. 优化内核TCP选项 P45

# Nginx配置优化 #
1. 关闭访问日志, 仅开启重要的日志
2. 使用epoll
3. 配置:
	1. worker_connections 65535
	2. keepalive_timeout 60
	3. client_header_buffer_size 8k, 通过getconf PAGESIZE来决定
	4. worker_rlimit_nofile 65535

# Nginx如何处理一个请求 #
## ip/域名部分的处理 ##
首先nginx要决定哪一个Server来处理这个请求
用户请求的url上的hostname, http头的Host 都是依据.
如果什么都不匹配上, 那么就会选择一个default_server (listen 80 default_server)
如果不想处理Host不明的请求, 可以这样:
```
server{
	listen 80 default_server;
	server_name _;
	return 444;
}
```
## uri部分的处理 ##
选择哪一个Location
优先级如下:
1. = 精确匹配
2. 无 精确匹配
3. ~/~*
4. 无 前缀匹配
5. 找不到 返回一个404
6. 对于同一类型, 按照顺序比

# 服务器名字 #
server_name 可以是 准确的名字, 还可以是带有通配符的名字, 还可以是一个正则表达式
名字的测试顺序(优先级)为:
1. 准确名字
2. 以*开头的名字
3. 以*结尾的名字
4. 正则表达式

server_name ~ ^(?<h>www\d+)\.nginx\.net$ 可以匹配 www3.nginx.net
对于包含{}两种花括号的正则表达式需要用""括起来; 否则会影响解析
可以使用正则表达式的命名捕获组, 比如上面就可以捕获到捕获组,将它命名为h
在下面可以使用 $h 进行引用它

如果你想让某台非 default_server 的serer 处理 请求头没有包含Host的请求, 那么给server_name 空字符串名字  ""
如果客户端使用包含ip地址的url来请求, 那么host可能会自动被设置成IP地址
此时需要给 处理的server 一个 name 为server的IP地址

server_name 还可以设置成一个无效的名字, 常用 _ 据说其他的名字也行 -;
他们是无效的域名, 从来不会与任何名字进行匹配

sever_name 还可以是 一个星号 "*", 但是它不是表示匹配所有域名
它提供的功能已经被 server_name_in_redirect取代了, 建议不要使用*

## 名字优化 ##
Nginx实现了一个3 hash table 用于快速搜索匹配的名字
具体来说就是 对于一个 名字: nginx.org
会分别生成三个key:
nginx.org
org
nginx
这样在搜索谁匹配 *.org 的时候就可以找到nginx.org


# 使用TCMalloc库 #
见第七章

# Nginx高可用的实现 #

# 限速 #
limit_rate 4k; 限制每个连接每秒只有4kb的流量
注意这里限制的是连接, 如果有人开多线程的话, 就可以突破这个限制.
默认是 no, 不限速
limit_rate_after 3m; 在全速下载3mb后开始限速;

# 限制用户的并发连接数 #
通过limit conn模块可以限制同一个ip地址的并发连接数
```
http{
	limit_conn_zone $binary_remote_addr zone=one:10m;
	创建了一个zone, 保存在内存里, 最大大小是10MB, zone的名字叫做one, 对于每一个客户端的请求, 以它的$binary_remote_addr 作为它的key
	因此对于来自用一个客户端的请求, 它的key都是一样的
	下面的与limit_conn配合 就可以限制一个客户端只能有一个连接请求!
	如果多个人有相同的key, 那么只能有一个人可以有一个连接请求.
	limit_conn_status 502; 意思是说 当连接超过了之后, 有新的链接再过来就让给它一个502
	server{
		location /download/ {
			limit_conn one 1; 设定了一个zone的名字 和 一个值; 这个zone里面的成员的连接数不可以超过这个值;
		}
	}
}
```

# 修改或隐藏Nginx的版本号 #
server_tokens off; 不显示nginx的版本号
修改nginx的版本号
修改
/src/core/nginx.h文件里的两个宏 NGINX_VERSION NGINX_VER 就可以修改成你自己的名字...

# 访问控制 #
allow/deny all;
allow/deny 127.0.0.1;
allow/deny 127.0.0.1/24;
注意解析的顺序是从上到下

# autoindex #
autoindex on;
autoindex_exact_size off;
autoindex_localtime on;

# 编码 #
charset utf8;
可以自动在响应头上加上 content-type= ... charset=utf-8
可以用你的开发者工具看到效果

# gzip #
gzip on; 启动压缩
gzip_min_length 100; 最小大小要达到100字节才启动压缩;
gzip_types text/plain application/xml; 对这2种类型也启动压缩, 默认只对text/html压缩;
gzip_comp_level 压缩比 1~9 越高越小越慢
gzip_proxied
	如果一个请求是通过代理过来的(可以通过Via头判断), 那么根据以下情况判断对它的响应是否要压缩. 具体看文档去
	
还有gzip_static, 这个模块默认没有参与编译
启动了之后 gzip_static on,
如果要访问1.xml 如果同目录下还有一个1.xml.gz 那么就使用后者
注意你要保证两者的时间戳一直, 否则会出现一些问题 具体看文档.

gunzip 默认也没有参加编译
gunzip on; 可以和gzip等一起用
当客户端不支持gzip的时候, 它就不会让gzip生效.
--with-http_gzip_static_module

# 日志 #
用log_format声明一段日志的模板
log_format gzip '$remote_addr - $remote_user [$time_local] $uri'

access_log path format options;
记录访问日志

open_log_file_cache
用于保存常用的日志文件的fd, 但是要求日志文件的名字包含有变量
可能是因为变量的原因, 所以默认是不缓存的吧, 所以如果不含有变量, 那么它对应的fd默认应该是缓存的吧?

# map模块 #
```
map $http_host $name {
	hostnames;
	default 0;
	example.com 1;
	*.example.com 1;
	test.com 2;
	*.test.com 2;
	~^还可以是一个正则表达式$ 3;
}
```
根据$host_name的值, 为$name赋值, 这个$name变量可以在其他地方进行使用
map里有3个特殊值:
default 表示默认值
hostnames 允许使用通配符来匹配主机名
include 包含其他文件
map_hash_max_size
	这里到底是表示整个hash表的总大小, 还是只元素的个数?
map_hash_bucket_size
	hash里每个元素的最大大小
但是这两个参数控制起来并不准啊, 建议大概一下就行了.

```
map $uri $site {
	/mail http://mail.xzc.com
}
```

# Limit Request 模块 #
limit_req_local_level limit_req_zone limit_req
可以用ab工具来测试效果
ab -n 10000 -c 100 http://www.baidu.com
并发100访问百度10000次

limit_req zone=name burst=number nodelay;
启动限制, 使用name域 突发可以有number
使用了nodelay, 当连接超过的时候就会立即返回错误, 否则会尝试阻塞
如果数据量比较大当然还是nodelay比较好吧

limit_req_log_level 级别
limit_req_status code
	当超过连接数的时候返回的code

limit_req_zone key zone=name:size rate=rate;
建立一个zone, 以key为关键字, 以name为名, 大小为size,
速率为 rate ( 2r/s表示每秒有2个请求, 10r/m 1分钟10个请求 )


# 管理HTTP头 #
add_header 加头
只有在code=200 204 301 302 304才有效
expires 使超时
expires [modified] | time @time-of-day|epoch|max|off
```
expires    24h;
expires    modified +24h;
expires    @24h;
expires    0;
expires    -1;
expires    epoch;
expires    $expires;
add_header Cache-Control private;
```
ngx_headers_more
增删改头
epoch 超时时间为1970年...
max 几乎是永久缓存
[modified] time
	time为负数表示nocache
如果有一个modified就表示 过期的时间是 该文件的最后的修改时间+time
为什么浏览器明明都说no-cache了还是有304啊?
因为no-cache表示消息不缓存, 如果要使用的话, 得先发一个请求到服务端问一下文件是否改变.

more_set_headers -s 404 -t 'text/plain' 'X-Foo: Bar'
-s
-t
当相应的code与-s指定的相同, content-type与-t的相同时才生效

more_[set|clear]_[input_]headers
input表示用来修改客户端的请求头

Transfer-Encoding:chunked
当服务器无法事先知道Content-Length的时候, 可能会使用chunked模式进行传输



# 重写URI #
rewrite pattern replacement flag;
flag
	1. last 在搜索到相应的URI和location之后完成rewrite指令
	2. break 完成rewrite指令处理
	3. redirect 302
		1. Host
		2. server_name hostname
		3. default_server
		4. ip
	4. permanent 301

用?防止追加args

server上的rewrite会先生效
last
break break出那个ngx_rewrite循环, 不再进行rewrite操作
完成当前的规则组, 不在处理其他的rewrite
if(条件){...}
= != ~ ~* !~ !~* -f !-f -d !-d -e !-e -x !-x
return 结束执行规则, 产生返回码

rewrite_log
set var value
if(...){
	limit_rate 10k;
}

# ssi #
Server Side Include
ssi on;
一些指令
config set echo if else elif endif


# X-Sendfile #
1. 假设要提供有权限的用户下载文件的服务.
2. 验证用户是是否有权限当然是有后面的服务器来做的
3. 然后提供下载文件的最好是nginx或其他的静态服务器, 不然后台服务器的压力挺大
4. 一般情况下要达到这样的效果, 需要2和3配合
5. 在nginx里, 只要代理服务器返回了一个 X-Accel-Redirect
6. nginx就会将请求在内部重定向到期指定的URI, 这样就下载了
7. 不过还是需要两者配合一下

以php为例子
```
<?php
if (isset($_GET['f'])) {
	header('X-Accel-Redirect: /files/'.$_GET['f']); 返回这个头指定文件的位置
	header('Content-Type: application/force-download');//来一个强制下载, 如果不指定content-type的话, 很有可能默认是text/html 这将会导致数据文件在浏览器以html的形式打开 形成乱码
	header('Content-Disposition: attachment; filename="'.$_GET['f'].'"');//强制下载
}else{
	echo '没有这个文件';
}
?>
location /files/ {
	internal;防止直接访问
	root html;
}
```
另外需要注意 proxy_temp_path 这个东西, 当从代理服务器拿东西的时候, nginx会进行缓存, 一定要保证你指定的user用户有权限可以去进行读写
否则就会出错, 客户端不会受到任何的数据(empty response), 然后在error_log 里会有 类似 没有权限 的字样

# 在Nginx的响应体之前或之后添加内容 #
addition模块, 需要重新编译 --with...

不能含有变量
add_after_body
add_before_action
使用了这些命令之后会使得Transfer-Encoding:chunked


就是可以在一个URL响应体的前面和后面添加其他内容
这样就可以用来做模板了?


# Nginx与访问者的地理信息 #
http_geoip_module
需要geo数据库和读取数据库的库文件
--with-http_geoip_module

用ldd可以查看某个程序所需要的链接库的情况

# 防盗链 #
## Referer模块 ##
这个模块默认是启动的
valid_referers none blocked www.a.com  mail.a.com;
这个指令用于说明哪些referer是有效的, 其中none的意思是没有referer.
blocked表示一个特殊的Referer, 具体看文档, 也被认为是有效的Referer
如果是无效的referer, 那么 $invalid_referer =1 可以用这个来判断, 返回一个403
名字可以使用*

## SecureLink模块 ##
一般这样用:
secure_link $arg_md5,$arg_e;
这句话表明哈希值保存在uri的md5参数上, 然后e参数用来做超时检测
e参数可以不指定, 那么表示不会超时

secure_link $secure_link_expires$uri,xzc;
这句话表明对于每个请求, 以上面这个格式进行哈希, 然后作为验证的依据
$secure_link_expires指的就是你上面指示的$arg_e, 如果你到时传进来的e=123, 那么它的值也为123

验证步骤
1. 先检测哈希值是否匹配
	1. 如果哈希不匹配, 那么$secure_link=''
2. 再来检测是否超时
	1. 如果超时 $secure_link="0"
3. 否则验证成功 $secure_link="1"

假设
secure_link $arg_md5,$arg_e;
secure_link $secure_link_expires$uri,xzc;

当访问 /p/1.txt 的时候, 需要提供md5和e参数
假设访问/p/1.txt, 假设选了一个时间戳 1456829992 (2016/3/1 18:59:52)
通过如下的方式生成md5
echo -n '1456829992/p/1.txt,xzc' | openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =
得到md5=kVHteWGjbiBIjoR5BtT5dA
因此最后的uri是 /p/1.txt?e=1456829992&md5=kVHteWGjbiBIjoR5BtT5dA
验证的结果是 $secure_link="0" 表明md5是正确的, 但是这个连接已经超时了, 因为现在的时间比 2016/3/1 18:59:52 大

假设又选了另外一个时间1456839992, 假设还没有超时
echo -n '1456839992/p/1.txt,xzc' | openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =
得到md5=ZzmQvdz7_6wVi0tobPc0fA
因此最后的uri是 /p/1.txt?e=1456839992&md5=ZzmQvdz7_6wVi0tobPc0fA
这个md5是正确的, 而且没有超时, 因此 $secure_link="1" 然后你就可以正确访问数据了

# stub_status #
--with-http_stab_status
```
location /status{
	stub_status on;
}
```
再去访问
http://ip/status
就会显示一些简单的nginx的监控信息
```
Active connections: 2 当前活动的客户端数, 包括正在等待的连接
server accepts handled requests
 2 2 1 
 已经接受了的客户端的数量 已经处理了的客户端的数量(一般来说是和已经接受了的客户端的数量相等的, 除非某些限制, 比如worker_connections) 客户端的请求书
 Reading: 0 Writing: 1 Waiting: 1
正在读请求头的数量 正在写响应的数量 客户端请求正在等待处理的数量
```


# 对内容体的替换 #
--with-http_sub_module

sub_filter </head> '</head><script>...</script>';
sub_filter_once on/off; 是否只替换一次
sub_filter_types text/plain;
默认对text/html进行替换, 其他类型需要指定.

# Nginx的基本认证方式 #
## htpasswd的用法 ##
htpasswd -cdb file username passwod
-c表示创建一个新文件 -d表示加密密码 -b表示从控制台读取直接指定密码

auth_basic 'xzchaoo';
auth_basic_user_file conf/htpasswd;
htpasswd文件用上面的方法进行建立.

# cookie #
在userid模块里
提供了2个变量 $uid_got $uid_set

```
userid on;
userid_domain xxx.com;
userid_expires time|max;
userid namel
userid_p3p line;
userid_path /;
userid_service address;
```

# Nginx基于客户端请求头的额访问分类 #
ngx_http_split_clients_module
基于某些条件(IP,头,cookie)将客户端访问的资源分开
```
split_clients "${remote_addr}AAA" $variant {
	0.5% .one;
	2.0% .two;
	* "";
}
server{
	location{
		index index${variant}.html
	}
}
```
完全不知道在干嘛!

# 通过UpStream模块使得Nginx实现后台服务器集群 #
```
upstream backend{
	ip_hash;#通过ip_hash的方式路由客户端请求 , 不能与weight同时使用
	server s1.aaa.com;# weight=5; 表示这个server更有可能被选中
	server s2.aaa.com:8080;
	server s3.aaa.com down; down表示这个服务器坏掉了
}

server{
	location / {
		proxy_pass http://backend;
	}
}
```


#  #
expires和ETag的区别
以expires为缓存的方式是使用了时间缓存, 就是对上一次是200的请求, 如果再次访问它, 就会带上一个 if-modified-since 头
如果没修改过就返回304
而etag的值没有过多的限制, 就是一个字符串而已, 至于这个字符串是根据什么生成的(比如根据文件的最后修改时间, 精确到秒级别)
只需要这个值跟服务器产生的etag不匹配 就算失败(所以服务器还要动态计算ETag?)


Drupal


# systemd #
centos7开始, 使用systemd来管理系统的服务
## systemctl ##
systemctl set-default multi-user.target 启动的时候默认进入终端模式
systemctl set-default graphical.target 默认是图形界面
enable/disable 控制开机启动
start stop reload restart status 如往常

# varnishlog #
-b 只输出和backend的交互
-c 只输出和client的交互
-g request/session/vxid/raw 分组
-i 只包含相应的标签的行``` -i Begin,Ene,Req*,Resp*```
-q 查询条件 -q 'RespStatus < 500' , -q 'ReqURL eq "/" '

# HTTP缓存相关的头 #
1. Expires
2. Cache-Control
3. Etag, 返回请求的一个特征码
4. Last-Modified, 返回文件的修改时间
5. If-Modified-Since, 带上上一次请求的文件的修改时间, 如果修改时间一致, 那么就认为文件没有改变
6. If-None-Match, req带上上一次请求的文件的特征码, 如果特征码一致, 那就认为文件没有改变
7. Vary
	1. 用于表示一个连接的特征, 如果为空的话, 那么可能这个连接的特征就只由它的url来决定(某些请求头不一样不要紧)
	2. 如果 Vary: Cookie, XXX
		1. 意思是说如果两次请求请求了相同的url, 但是他们带来的Cookie头和XXX头, 不一样, 那么认为他们请求的不是同一个文件
8. Age, 一般是由缓存服务器写的头, 表示这个对象已经在缓存里呆多久了, 单位是秒
9. Date
10. Pragma

Req可以带的
1. no-cache 在没有服务端的同意下不要使用缓存的内容
2. no-store 不允许保存, 适用于私有缓存和共享缓存

Resp可以带的
1. must-revalidate 必须要通过服务端的验证
2. no-cache
3. no-store
4. no-store
5. public
6. private
7. max-age
8. Expires
9. Pragma

