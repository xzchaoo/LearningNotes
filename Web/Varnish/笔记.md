https://www.varnish-cache.org/

#  #
https://www.varnish-cache.org/docs/4.0/tutorial/introduction.html
1. Varnish is a caching HTTP reverse proxy.
2. 从客户端接收请求, 然后尝试使用它的缓存进行响应.
3. 如果找不到缓存就向将请求路由给backend
4. 然后敬爱给你backend的结果保存到缓存
5. 可以指定什么东西可以缓存
6. VCL

http://127.0.0.1:6081/
如果backend是http://127.0.0.1:8080
如果8080没有打开, 那么varnish会返回一个503
/etc/varnish/default.vcl
可以修改成如下 进行测试
```
vcl 4.0;
backend default {
    .host = "www.varnish-cache.org";
    .port = "80";
}
```
service varnish reload
service varnish stop
/etc/sysconfig/varnish.
```
DAEMON_OPTS="-a :6081 \
             -T localhost:6082 \
             -f /etc/varnish/default.vcl \
             -S /etc/varnish/secret \
             -s malloc,256m"
Change it to:
DAEMON_OPTS="-a :80 \
             -T localhost:6082 \
             -f /etc/varnish/default.vcl \
             -S /etc/varnish/secret \
             -s malloc,256m"
```
backend服务器
用于真实提供内容的服务器, varnish会对它的内容进行加速

origin服务器


varnishadm
admin console
用户需要有权限读取 /etc/varnish/secret
可以停止和启动 cache process
加载VCL
调整内置内置的 load balancer
使缓存无效
有一个help指令


varnishlog
记录日志, 但是这个是内存级别的日志

# The Varnish Users Guide #
有两个关键的进程
1. the manager, 用于和管理员对话, 通常以root权限运行
2. the worker, 或叫子进程, 做实际的工作, 通常以比较小的权限运行
	1. 可交互的, 提供了一个命令行接口, 提供了几乎所有的控制
	2. 命令行可以远程调用, 需要有一个PSK(Pre Shared Key)
3. VCL
4. varnishlog varnishstats varnishncsa

在/etc/varnish/secret存放了一个key
varnishd [...] -S "" [...]
启动的时候使用-S指定这个key文件, 当然默认位置就不用指定了

centos7 改用 systemctl 的方式控制服务

systemctl action ServiceName
start stop reload restart kill

# 函数 #
1. ban (expression)
2. call (subroutine)
3. hash_data (input)
4. new
5. return
6. rollback
7. synthetic
8. regsub
9. regsuball

# 常见对象 #
## server ##
1. identity
2. ip
3. hostname

## storage ##
1. <name>.free_space 可读
2. <name>.used_space 可读
3. <name>.happy 可读

## req ##
客户端发起的请求
1. backend_hint 设置这个请求将会被路由到哪个backend
2. can_gzip 只读, 是否愿意gzip
3. esi 设置成false的话可以禁用esi功能(不管其他值如何设置, 默认是true), 避免使用这个变量
4. hash_always_miss 设置成true的话 故意造成miss
5. http.xxx 请求头
6. method 方法, 都是大写的
7. proto
8. restarts 记录这个请求重试的次数, 遇到某些错误时, varnish内部可能会让一个请求重新发起多次
9. ttl
10. xid, 这次请求的唯一标识符, 找日志的时候有用
11. url 请求的url
5. hash_ignore_busy
5. esi_level

## resp ##
返回给客户端的内容
1. http.xxx
2. proto
3. reason
4. status
5. 

## beresp, backend的resp ##
1. backend.ip 后台的ip
2. backend.name 后台的name
3. do_esi 默认是false 是否要启动esi功能
4. do_gunzip 默认是false, 是否要将后台返回的gzip数据解压缩后才 放缓存和给客户端
5. do_gzip 默认是false, 是否要修改客户端的请求头(如果客户端愿意接受gzip), 使得客户端只请求gzip(因为客户端可能愿意接受的encoding不止一种), 如果服务端也返回gzip的数据, 那么就成了
5. grace 设置一个时间, 让这个请求对应的缓存即使超时了也能够被使用
6. http.XXX 获取http头
7. status/reason 返回的code和描述
8. ttl 超时时间
uncacheable
storage_hint
proto
keep
do_stream

## client ##
表示客户端
1. identity 用于标识客户端
2. ip 客户端的ip

## obj ##
1. grace
2. hits	
3. http 请求头
4. keep
5. proto
6. reason
7. status
8. ttl
9. uncacheable (pass or hit-for-pass)

## 其他变量 ##
now 起点是epoch, 单位是秒

# actions #
1. pass
	1. 将请求直接扔给服务器, 将服务器的返回直接扔给客户端, 不进行缓存
2. pipe


1. 允许你控制hash算法
	1. 默认的实现是host+url
	2. 你可以将cookie等考虑进去

1. varnishd
	1. 从clients接受http请求, 将请求发送给一个后端, 缓存后端的响应, 并发送给客户端.
2. varnishtest
	1. 用来测试的
3. varnishadm
	1. 管理工具
	2. start/stop varnished
	3. change configuration parameters
	4. reload VCL
	5. 查看参数的解释
4. varnishlog
5. varnishstat
	1. 用于查看全局的计数器

# VTC #
```
varnishtest "Varnish as Proxy" //测试的名字

server s1 { //定义了一台假服务器, 名字必须s开头
   rxreq //允许接受请求
   expect req.url ~ "/bar"
   txresp //允许响应请求
   #txresp -gzipbody {[bar]}
   #txresp -body {<h1>FOO<esi:include src="/bar"/>BARF</h1>} -hdr "foo:1"
   
} -start //启动, 这会使得${s1_addr}和${s1_port}变成某个有效值, 用于指向这台服务器

varnish v1 -arg "-b ${s1_addr}:${s1_port}" -start //定义一台真实的varnishd服务器, 名字必须v开头
//使用-arg来指定这台varnishd服务器的启动参数

client c1 {
      txreq -url "/bar" -hdr="Accept-Encoding:gzip"
      rxresp
      gunzip
      expect resp.bodylen == 5;

      expect resp.http.via ~ "varnish"
} -run
```
1. varnish是多线程的
2. 使用 -wait 启动同步机制
3. -run=-start -wait

如果需要写日志的话
[3] There is no configuration file. Use the command systemctl start/stop/enable/disable/ varnishlog/varnishncsa instead.

vernishlog -q 'RespStatus == 200'

# 存储 #
免费版主要支持 malloc file
似乎重启了数据就全丢了
当你内存足够大的时候使用malloc, 如果你malloc太大的话, 那么实际上有一部分的数据会和硬盘作交换的
如果要缓存的内容大大超过内存, 那么就使用file, 它会尽量映射一个文件到内存里
http://book.varnish-software.com/4.0/chapters/VCL_Basics.html


# 杂 #
1. 对于Centos7, 其配置文件默认在/etc/varnish/下
2. /etc/varnish/varnish.params 这个文件用于设定Varnish子进程的参数
3. firewall-cmd --query-port=80/tcp
4. firewall-cmd --zone=public --add-port=80/tcp --permanent
5. firewall-cmd --reload


# 清除缓存的策略 #
1. 对某个地址发送PURGE方法
	1. 因为一般能够进行缓存的肯定是通过get或head方法获得的结果
	2. 因此缓存的key一般是通过url构造
	3. 所以仅仅将方法名换成PURGE, 也能够得到相同的key
	4. 这样就可以驱逐该缓存出去了
2. 执行ban指令
	1. ban( req.url ~ /user && req.http.host ~ abc.com ) 
	2. 这个方法或创建一个ban对象
	3. 以后每当一个对象hit了, 这个对象就会拿出来和所有的ban进行对比, 如果满足ban条件的话, 那么它就被删除, 导致一个miss
	4. 可以用的对象有 req.*, obj.*
	5. 似乎没有提供删除ban的功能, ban会在它比当前最旧的obj还有旧的时候被删除, 用不好的话会影响性能
	6. 建议在ban表达实例不要使用req对象, 而是只是用obj对象, 这样叫做 lurker-friendly bans
	7. 对象将会在被hit的时候 或 lurker主动找到它的时候进行ban的验证
	8. 默认情况下, obj并没有保存请求的url
		1. 但是它有保存请求的http头!
		2. 因此你可以在 vcl_backend_response主动将url写入头里, 然后对象就会带着这个头缓存
		3. 但是记得在vcl_deliver里要用 unset resp.http.你的特殊的头 删掉, 仅作为内部使用


txresp
1. -proto HTTP/1.1
2. -status 200
3. -msg foo
4. -body "i am body"
5. -hdr "foo:1"
6. -gzipbody FOO
7. -nolen -hdr "Transfer-encoding:chunked"
8. chunkedlen 30000
9. chunkedlen 0
10. 
txreq
1. -req GET
2. -proto HTTP/1.0
3. -url /foo.html
4. -body "i am bbodylenody"

req/resp
1. bodylen
2. http.X-abc

gunzip

shell "echo 'vcl 4.0; backend foo { .host = \"${s1_addr}\"; .port = \"${s1_port}\"; }' > ${tmpdir}/_b00014.vcl"

expect resp.http.X-Test == <undef>
varnish v1 -arg "-s malloc" -vcl+backend {} -start
varnish v1 -vcl+backend { } -start
# Give varnish a chance to update stats
delay .1

varnish v1 -expect sess_conn == 2
varnish v1 -expect cache_hit == 1
varnish v1 -expect cache_miss == 1
varnish v1 -expect client_req == 2
varnish v1 -expect s_sess == 2
varnish v1 -expect s_req == 2
varnish v1 -expect s_fetch == 1
expect

delay
复杂的字符串可以用{}包起来

# 健康检查 #
```
backend s1 {
	.host ="1.1.1.1";
	.port = "80";
	.probe = {
	 	 .url = "/healthtest";
	        .timeout = 1s;
	        .interval = 4s;
	        .window = 5;
	        .threshold = 3;
	}
}
```
probe对象可以单独定义:
```
probe www_probe {
    .url = "/health";
    .url也可以替换成:
    .request = "GET / HTTP/1.1" "Host: www.abc.com" "Connection: close";
}
然后backend里只要写 .probe = www_probe;就行了
```
每4秒发已过期请求给 http://1.1.1.1:80/healthtest, 如果5次内成功3次就算存活, 每次连接超时1秒.
这个地址必须返回200, 404之类的就算是失败.

使用如下的命令观察健康状态
varnishlog -g raw -i Backend_health

或进入 varnishadm 执行backend.list也可以看到
http://book.varnish-software.com/4.0/chapters/Saving_a_Request.html


1. 
默认情况下如果请求带有cookie, varnish会默认返回pass, 你可以在vcl_recv里强制返回 hash.
服务端需要返回Vary: Cookie, 这样Cookie不同也会被当做不同的对象
这样的结果是一个hash对应了多个对象

2.
另外一种策略是将cookie带入hash算法中
这样的结果是一个hash对应一个对象
purge的时候只会清除一个, 当然你purge的时候需要带上相应的cookie

1. purge
	1. 将会清除同一hash的所有变体
	2. 靠Vary区别的请求具有相同的hash
	3. 因为默认情况下Vary指定的字段(比如Cookie)没有参与到hash过程中

Despite cookie-based caching being discouraged, Varnish can be forced to cache content based on cookies. If a client request contains req.http.Cookie, use return (hash); in vcl_recv. If the cookie is a Set-Cookie HTTP response header field from the server, use return (deliver); in vcl_backend_response.


# cookie模块 #

```
sub vcl_recv {
        cookie.parse(req.http.Cookie);
}
get(STRING cookiename)
cookie.parse("cookie1: value1; cookie2: value2;");
std.log("cookie1 value is: " + cookie.get("cookie1"));
cookie.set("cookie1", "value1");
std.log("cookie1 value is: " + cookie.get("cookie1"));
isset(STRING cookiename)
cookie.delete("cookie2");
filter_except
sub vcl_recv {
        cookie.parse("cookie1: value1; cookie2: value2; cookie3: value3");
        cookie.filter_except("cookie1,cookie2");
        // get_string() will now yield
        // "cookie1: value1; cookie2: value2;";
}
set req.http.cookie = cookie.get_string();
format_rfc1123(TIME, DURATION)
sub vcl_deliver {
        # Set a userid cookie on the client that lives for 5 minutes.
        set resp.http.Set-Cookie = "userid=" + req.http.userid + "; Expires=" + cookie.format_rfc1123(now, 5m) + "; httpOnly";
}
```

# ESI #
<esi:remote></esi:remove>
<!--esi<esi:include></esi:include>-->
主要用于解决如下场景:
1. 有一个新闻的页面, 里面显示了该新闻的内容, 同时旁边有一个最新新闻列表
2. 显然这个新闻的内容一般是不会变的, 而最新新闻列表是会变的
3. 利用ESI就可以比较好的解决这个问题
4. 我想另外一种解决的方案就是使用静态html页面+ajax吧?

```
When using ESI, Varnish fetches the news article from a web server, then parses the <esi:include src="/url" /> ESI tag, and fetches the URL via a normal request. Either finding it already cached or getting it from a web server and inserting it into cache.
The TTL of the ESI element can be 5 minutes while the article is cached for two days. Varnish delivers the two different objects in one glued page. Thus, Varnish updates parts independently and makes possible to combine content with different TTL.
```

1. 允许ESI
	```
	sub vcl_backend_response {
    		set beresp.do_esi = true;
	}
	服务端在返回的页面里嵌入<esi>标签
	```
	
	
1. vcl_recv
	1. 重定向
	2. 重写url
	3. 管理http头
2. vcl_pass
	1. 当cache被pass时 (可能是显式的 或 是由于hit_for_pass, uncacheable)
	2. hit-for-pass 就是它会创建一个特殊哈希对象, 占据相应的hash位置, 它也可以有TTL
	3. 但是该对象 obj.uncacheable == true, 然后会导致被pass
3. vcl_backend_fetch
	1. 当要发请求给后台时
	2. 可以临时对bereq jinxing xiugai 
4. vcl_hash
	1. 当需要对请求做哈希的时候进来
	2. 你可以不断调用hash_data添加哈希的关键字
	3. 你可以模仿内置的vcl_hash程序
5. vcl_hit
	1. 当对象在缓存里找到的时候
	2. 建议模仿内置程序
	3. 结合 健康检查 可以做得更好, http://book.varnish-software.com/4.0/chapters/Saving_a_Request.html#grace-mode
6. vcl_miss
	1. 当在缓存里没找到的时候
	2. 一般是返回 (fetch)
	3. 在这里可以移除X-Varnish头, 避免它发给backend
7. vcl_deliver
	1. 基本上是最后一步 
	2. 在这里可以修改返回给client的resp
8. vcl_synth
	1. Varnish用于生成信息
	2. 处理错误信息
	3. 用于做重定向(目前没有其他更简单的办法)
	4. synthetic("")可以用于控制输出的内容
9. vcl_purge


# Actions #

set req.http.Cookie = "a:1;";
unset req.http.Cookie
if (req.url ~ "^/inde" && ... ) {
	...
}

# acl #
acl admins {
	"127.0.0.1";7
	"192.168.1.0"/24;  注意/24放在外面 并没有写错
	!"192.168"
}
if( ! client.ip ~ admins) {
	return (synth(405,"李大爷的"));
}

# directors #
1. round_robin 轮询
2. fallback 第一个不行了再去第二个...
3. random 随机
4. hash 哈希映射

