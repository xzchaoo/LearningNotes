# 下载 #
http://www.rabbitmq.com/download.html

# 安装 #
需要先安装 Erlang
http://www.erlang.org/downloads

Port Access

Firewalls and other security tools may prevent RabbitMQ from binding to a port. When that happens, RabbitMQ will fail to start. Make sure the following ports can be opened:

4369 (epmd), 25672 (Erlang distribution)
5672, 5671 (AMQP 0-9-1 without and with TLS)
15672 (if management plugin is enabled)
61613, 61614 (if STOMP is enabled)
1883, 8883 (if MQTT is enabled)
It is possible to configure RabbitMQ to use different ports.

# java客户端 #
http://www.rabbitmq.com/java-client.html
http://www.rabbitmq.com/api-guide.html
```
<dependency>
  <groupId>com.rabbitmq</groupId>
  <artifactId>amqp-client</artifactId>
  <version>3.6.5</version>
</dependency>
```

# 入门 #
http://www.rabbitmq.com/getstarted.html

Producing 发送消息
queue 有一个名字 消息暂存在对列里 一般没有大小限制
Consuming

通常情况下, worker 一收到消息 就返回ack, 所以如果worker处理到一半就挂了 那消息就丢了, 即 autoAck=true
你可以修改ack机制 即 autoAck=false

对于任务的执行没有超时这一说法, RabbitMQ 会监测worker是否挂了, 如果挂了就重新分给其他worker去做
There aren't any message timeouts; RabbitMQ will redeliver the message when the consumer dies. It's fine even if processing a message takes a very, very long time.


## ack ##
调用 basicConsume 的时候可以指定ack
使用 channel.basicAck(envelope.getDeliveryTag(), false); 手动发ack
```
channel.basicQos(1); // accept only one unack-ed message at a time (see below)

final Consumer consumer = new DefaultConsumer(channel) {
  @Override
  public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
    String message = new String(body, "UTF-8");

    System.out.println(" [x] Received '" + message + "'");
    try {
      doWork(message);
    } finally {
      System.out.println(" [x] Done");
      channel.basicAck(envelope.getDeliveryTag(), false); //执行完才发的ack
    }
  }
};
boolean autoAck = false;
channel.basicConsume(TASK_QUEUE_NAME, autoAck, consumer); //注册消费者的时候 指定 autoAck=false
```

忘记ack是严重的事情! 因为没有超时这一个设定, 所以直到该worker退出该认定消息发送失败, 然后重发, 这个过程会消耗很多东西

使用 rabbitmqctl 打印出未被ack的消息
sudo rabbitmqctl list_queues name messages_ready messages_unacknowledged

## durability ##
默认情况下 如果 RabbitMQ 退出或崩溃了 那么所有的对列和消息是会被丢弃的
除非你明确指出哪些该具有持久性, 消息和对列都需要具有持久性

### 持久对列 ###
```
boolean durable = true;
channel.queueDeclare("hello", durable, false, false, null);
```

### 持久消息 ###
通过 MessageProperties 实现了 BasicProperties 接口, 有一个静态变量 PERSISTENT_TEXT_PLAIN
```
import com.rabbitmq.client.MessageProperties;

channel.basicPublish("", "task_queue",
            MessageProperties.PERSISTENT_TEXT_PLAIN,
            message.getBytes());
```

仅靠上面的配置还没有完全的持久性!
> Marking messages as persistent doesn't fully guarantee that a message won't be lost. Although it tells RabbitMQ to save the message to disk, there is still a short time window when RabbitMQ has accepted a message and hasn't saved it yet. Also, RabbitMQ doesn't do fsync(2) for every message -- it may be just saved to cache and not really written to the disk. The persistence guarantees aren't strong, but it's more than enough for our simple task queue. If you need a stronger guarantee then you can use publisher confirms.


## 公平派发 ##
轮询并不总是好的 因为有的消息处理比较耗费资源
通过下面的代码, 一个worker在同一个时间只会有一个未被ack的消息
```
int prefetchCount = 1;
channel.basicQos(prefetchCount);
```

## 发布/订阅 即topic模式 ##

## 临时对列 ##
String queueName = channel.queueDeclare().getQueue();
非持久 排他 自动删除 随机名字

## 绑定队列 ##
将对列和一个交换所关联起来, 比如 fanout 类型的交换所的功能是将收到的消息发给它所知道的所有对列, 那它知道哪些对列呢? 就是绑定了
channel.queueBind(queueName, "logs", "");
注意 我们自定义的 logs 是一个 fout 类型的交易所, 它的 routingKey 是多少无所谓的 一般是 ""

## 绑定 ##
channel.queueBind(queueName, EXCHANGE_NAME, routingKey);
将该队列跟该交换所用指定的key关联起来, 需要考虑交换所的类型



# 杂 #
1. channel.basicQos(1) 同一时只会接收一个 未被ack的消息

## windows上重启rabbitmq的方法 ##

# 交易所 #
## direct ##
所有 routingKey 一致的消息会被转到该队列, 一个队列可以绑定多个routingKey
可以有多个 worker 有相同的 routingKey

适用于有等级的日志记录
routingKey 取 info debug warning 之类

```
channel.exchangeDeclare(EXCHANGE_NAME, "direct");
channel.basicPublish(EXCHANGE_NAME, YOUR_LOG_INVEL, null, message.getBytes());
```

## fanout ##

## topic ##
routingKey 要求具有一定格式, 一组单词用点号隔开, 比如 stock.usd.nyse
长度不超过255

一个消息会被发给 routeingKey想匹配的 队列
匹配规则:
```
* 表示一个单词
# 表示0个或多个单词
```

例子
```
*.orange.* 一共有3个单词 第二个单词是orange
lazy.# lazy为第一个单词, 接下来可以有0个或多个单词
```

### topic的退化 ###
当 topic 的 routingKey 不包含 #或* 的时候他就退化成了 direct 了
当 topic 的 routingKey 是 # 的时候 它就退化成 fanout 了

# RPC #
用消息中间件可以做出一个性能差的RPC
1. 发送一个消息, 设置消息的replyTo
```
callbackQueueName = channel.queueDeclare().getQueue();

BasicProperties props = new BasicProperties
                            .Builder()
                            .replyTo(callbackQueueName)
                            .build();

channel.basicPublish("", "rpc_queue", props, message.getBytes());

```
2. worker处理完消息之后将结果发给 replyTo, 结束.

# Message properties #
deliveryMode 描述这个消息是否是持久的 如果值是2就是持久的 否则都不是持久的
contentType 你传输的数据的mimie
replyTo 回复到哪里
crrelationId 相关联的id



# 注意 #
1. RabbitMQ 不允许你用不同的参数定义相同的队列
2. 往一个不存在的对列注册消费者会抛异常


# Spring AMQP #
1. 你的相关的 @Bean 都会被自动 declare, 比如Queue Binding Exchange
2. AmqpAdmin AmqpTemplate ConnectionFactory Queue Binding Exchange 匿名Queue BindingBuilder
3. ListenerContainer
4. @Queue @QueueBinding @SendTo


new Binding(someQueue, someDirectExchange, "foo.bar")
Binding b = BindingBuilder.bind(someQueue).to(someTopicExchange).with("foo.*");

AmqpTemplate 默认可以绑定 exchange 和 routeKey, 所以有的方法就可以省略着两个参数了

# ConnectionFactory #
host port username password vhost
cache 模式 chanel 还是 connection

SimpleRoutingConnectionFactory 支持将多个CF复合到一起 然后根据路由策略使用不同的CF
也可以手动处理:
```
SimpleResourceHolder.bind(rabbitTemplate.getConnectionFactory(), vHost);
rabbitTemplate.convertAndSend(payload);
SimpleResourceHolder.unbind(rabbitTemplate.getConnectionFactory());
```

获得 @RabbitListener相关的 container
通过 RabbitListenerEndpointRegistry 的 getListenerContainers()


# Publisher Confirms and Returns #
http://www.rabbitmq.com/blog/2011/02/10/introducing-publisher-confirms/
publisherConfirms
publisherReturns

有的时候我们需要确保说broker已经成功收到该消息了(持久化到硬盘), 此事可以使用事务
发送者要这样:
```
ch.txSelect();
for (int i = 0; i < MSG_COUNT; ++i) {
        ch.basicPublish("", QUEUE_NAME,
                            MessageProperties.PERSISTENT_BASIC,
                            "nop".getBytes());
        ch.txCommit();#提交事务 然后下次的代码会自动启动一个事务
}
```
接受者要这样:
```
QueueingConsumer qc = new QueueingConsumer(ch);
ch.basicConsume(QUEUE_NAME, true, qc);
for (int i = 0; i < MSG_COUNT; ++i) {
        qc.nextDelivery();
        System.out.printf("Consumed %d\n", i);
}
```

但是效率比较低

confirm 模式不支持事务 两者只能取一个
当调用 select 的时候就进入了 confirm 模式
然后你需要设置一个 confirmListener 它会接受消息的ack情况
此后你的消息会有一个 deliveryTag 从1开始递增

```
private volatile SortedSet<Long> unconfirmedSet =
    Collections.synchronizedSortedSet(new TreeSet());

...

ch.setConfirmListener(new ConfirmListener() {
    public void handleAck(long seqNo, boolean multiple) {
        if (multiple) {
            unconfirmedSet.headSet(seqNo+1).clear();
        } else {
            unconfirmedSet.remove(seqNo);
        }
    }
    public void handleNack(long seqNo, boolean multiple) {
        // handle the lost messages somehow
    }
});
ch.confirmSelect();
for (long i = 0; i < MSG_COUNT; ++i) {
     unconfirmedSet.add(ch.getNextPublishSeqNo());
     ch.basicPublish("", QUEUE_NAME, MessageProperties.PERSISTENT_BASIC,
                       "nop".getBytes());
 }
while (unconfirmedSet.size() > 0)
     Thread.sleep(10);
```


> an un-routable mandatory or immediate message is confirmed right after the basic.return;
otherwise, a transient message is confirmed the moment it is enqueued; and,
a persistent message is confirmed when it is persisted to disk or when it is consumed on every queue.

# 构建消息 #
```
Message message = MessageBuilder.withBody("foo".getBytes())
.setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN)
.setMessageId("123")
.setHeader("bar", "baz")
.build();
```


```
MessageProperties props = MessagePropertiesBuilder.newInstance()
.setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN)
.setMessageId("123")
.setHeader("bar", "baz")
.build();
Message message = MessageBuilder.withBody("foo".getBytes())
.andProperties(props)
.build();
```


# 接收消息 #
## 轮询 ##
通过 receiveTimeout() 方法设置一个时间 然后如果超时就返回null 你自己可以加一个循环构成轮询
总之去看一下 receive* 系列方法就行

## 监听 ##
MessageListener
MessageListenerAdapter 可以让pojo来处理消息
SimpleMessageListenerContainer 和 jms 里面的概念是一样的

19748139

推荐使用 AnonymousQueue 而不是 name="" 的Queue
他们之间的区别是 前者是在本地利用UUID生成的名字 而后者是 broker 生成的名字
1. 而程序启动的时候可能broker还没有启动
2. 如果连接断了再恢复 那么前者名字不变 而后者会变
3. 前者的话名字可以具有一定的格式



# 队列的参数 #
exclusive 这样这个队列只有你的应用程序能够消费(总之只有一个消费者) 别人是无法订阅这个队列的(即使别人知道这个队列的名字)
auto-delete 当最后一个订阅者取消订阅的时候就删除这个队列

一般匿名队列 = 唯一的名字 + exlucsive=true + auto-delete=true

# 杂 #
1. 尝试声明一个已经存在的队列: 如果你的参数完全一致, 那么没问题, 如果参数不一致就会出错, 可以令declare的 passive=true 这样如果队列存在 那么declare就成功, 否则不会创建队列而是返回一个错误, 这可以用来检测队列是否存在


# 交换器 #
direct 直接根据队列名字
topic 匹配key
fanout 完全相等的key
headers 允许根据header 而不是 routingKey 来匹配

# vhost #
相当于一个虚拟机 拥有自己的一套AMQP
我们如果不设定 vhost的话就是使用默认的 vhost:/

rabbitmqctl list_vhosts 列出所有可用的
rabbitmqctl add_vhost name
rabbitmqctl delete_vhost name
 
# durable #
将队列和交换所设置成durable 这样可以保证消息被持久化到硬盘
你的消息本身必须要设置成durable的才行, deliveryMode=2
所以一共要设置3个地方才行!
但是性能损失非常大


publisher confirm 发送方确认


# rabbitmqctl #

## 用户 ##
添加用户
add_user username password

删除用户
delte_user username

修改密码
change_password username newPassword

清除密码
clear_password username

验证一下账号密码是否正确
authenticate_user username password

list_users 列出用户

## vhost ##
add_vhost <vhost>
delete_vhost <vhost>
list_vhosts

如果不指定 -p <vhost> 默认应该就是对 / 进行操作
set_permissions [-p VHOST] <user> CONF WRITE READ
clear_PERMISSIONS [-P vhost] USERNAME

列出权限
list_permissions [-p <vhost>]

列出这个用户的权限
list_user_permissions <username>