# 可以用于 #
1. 流式数据的发布和订阅, 和消息队列很像
2. 容错的方式存储流式数据
3. 流式处理

常用于构建数据在多个系统之间流动的场景
构建实时处理程序, 数据流动到这个节点, 处理一下, 然后又流到下一个节点

kafka以集群的形式运行, 用topic来指数据流, 每一条数据包含一个key, value 和 timestamp

拥有的API
1. 生产者API
2. 消费者API
3. Stream API: 帮助实现流式处理器
4. Connector API: 用于将kafka和一些已有的系统联系起来, 比如DB

# 概念 #

## topics and logs ##
一个topic表示了一种类型的log的数据流, 支持多个生产者和消费者
每个topic可以分为多个partition, 写的时候数据会随机(可以控制?)写到某个parition里
每个parition具有order, 但是总体不具有order
每个partition里的对象有一个唯一的标识, 叫做offset, offset一定是递增的
kafka会保存所有的记录一定时间(可配置), 过期之后删除, 由于数据很大程度上是连续的, 因此效率很高

消费者正在消费数据的地方成为position, 消费者可以控制position的位置(所以你可以消费历史数据), 但通常position是不停地递增的

partition有助于分散数据, 每个partition可以被同时消费, 起到负载均衡的效果

每个parition可以以副本的形式分布在多台服务器上以起到容错的效果
每个partition会有一台服务器叫做leader, 其他叫做followers, leader完全负责该parition的读写, followers负责同步数据, 当leder挂了, followers就会顶上去
这里来的话似乎followers是不能分担读操作的?


## 生产者 ##
生产者可以发送消息到多个topics里, 生产者可以自己选择这条数据写到哪个parition里! 生产者可以采用各种策略来实现负载均衡

## 消费者 ##
介绍消费者之前要介绍消费者组

一个topic下可以有多个消费者组, 发送给一个topic的消息, 会被同时发送给所有的组
每个组里可以有多个消费者, 这些消费者共同去消费所有的partiton, 同组各个消费者消费的partition不能一样

如果一个消费者加入组, 那么他会尝试从其他消费者哪里抢来一些partition
如果一个消费者离开组, 那么他的partition就会被其他人瓜分了
每个组里的消息是有序的, 但是跨组就不能保证有序了

	1. 消费者有"消费组"的概念: 发送给每个topic的消息, 会被转发给该topic下的所有组
		1. 这样就可以起到 传统的 queue 和 topic 的效果
		2. 如果1个topic只有1个组, 那么就像传统Queue
		3. 如果1个topic有多个组, 那么就像传统topic
		4. 
## Guarantees ##
1. 某个生产者发给某个topic的某个partition的消息一定是有序的
2. 消费者会按记录的存储顺序看到记录
3. 如果一个toipc有N个备份, 那么可以容忍N-1台服务器的失败

## 卡夫作为消息系统 ##
传统的消息系统有两种模型, 队列 和 发布-订阅
队列: 一个消息只会被一个消费者消费
发布-订阅: 将记录广播给所有消费者
这两种方式各有优缺点
Q的优点是允许多个消费者消费一个队列, 可以起到负载均衡的效果, 缺点是Q的消息无法被重复消费
一旦这个消息被读过了, 那么久过了

传统的消息队列对于 Queue, 会按照消息存储的顺序交出所有消息, 在这里是有序的, 但是发出消息给消费者, 这个步骤是异步的
因此有可能消费者A先收到了一个比较晚的消息, 而消费者B后收到了一个比较早的消息
传统的消息队列为了避免这种情况, 有 "排他消费者" 的概念, 只允许一个消费者消费一个Q, 此时消费能力大大降低 (通常需要先考虑是否真的有这样的需求!)

卡夫卡有 parallelism 的概念, 对于每个topic, 卡夫卡可以保证有序消费(根据文档, 只能保证每个partition的有序消费, 总体的有序只能靠只有1个partition来保证), 并且支持多个消费者进行负载均衡
这是通过分配 topic 里的 partition 给每个消费者, 每个partition只会有一个消费者, 这样每个partition里就肯定是有序的了
因此消费者数量不能超过partition, 一个消费者可以消费多个partition

卡夫卡作为存储系统
任何消息队列都可以作为 生产者 和 消费者 之间的解耦的存储系统
卡夫卡的特殊之处在于, 卡夫卡会将数据写到磁盘上并且在多台服务器之间做备份, 卡夫卡允许生产者等待一个ACK信号, 这样可以保证数据一定完全写入到磁盘 [速度就慢一些了]
卡夫卡的数据存储结构非常好, 官方说50TB没问题

卡夫卡用于流处理
流处理 != 消费者 + 生产者
还可以聚合和join其他流

The streams API builds on the core primitives Kafka provides: it uses the producer and consumer APIs for input, uses Kafka for stateful storage, and uses the same group mechanism for fault tolerance among the stream processor instances.


;